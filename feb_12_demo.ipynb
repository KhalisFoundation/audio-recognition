{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipdb\n",
    "from util import (\n",
    "    prepare_dataset,\n",
    "    build_model,\n",
    "    train,\n",
    "    plot_history,\n",
    "    plot_confusion_matrix,\n",
    "    TRAIN_DATA_PATH,\n",
    "    TEST_DATA_PATH,\n",
    "    BATCH_SIZE,\n",
    "    PATIENCE,\n",
    "    SAVED_MODEL_PATH, \n",
    "    SAVED_JS_MODEL_PATH,\n",
    "    LEARNING_RATE,\n",
    "    EPOCHS,\n",
    "    LABELS\n",
    ")\n",
    "import librosa\n",
    "import numpy as np\n",
    "import prepare_dataset as adprep\n",
    "import IPython\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "from split_dataset import create_test_split\n",
    "\n",
    "\n",
    "# You should only do this once!\n",
    "CREATE_TEST_SPLIT = False\n",
    "\n",
    "\n",
    "if CREATE_TEST_SPLIT:\n",
    "    create_test_split()\n",
    "\n",
    "\n",
    "\n",
    "DO_TRAIN_DATA_AUGMENTATION = False\n",
    "SAMPLES_TO_CONSIDER = 22050\n",
    "\n",
    "# IPython.display.Audio(\"my_audio_file.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \n",
    "\n",
    "    X_train, y_train, X_validation, y_validation = prepare_dataset(TRAIN_DATA_PATH)\n",
    "\n",
    "    # create network\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "    model = build_model(input_shape, learning_rate=LEARNING_RATE)\n",
    "\n",
    "    # train network\n",
    "    history = train(model, EPOCHS, BATCH_SIZE, PATIENCE, X_train, y_train, X_validation, y_validation)\n",
    "\n",
    "    # plot accuracy/loss for training/validation set as a function of the epochs\n",
    "    plot_history(history)\n",
    "\n",
    "    \n",
    "    # save model\n",
    "    model.save(SAVED_MODEL_PATH)\n",
    "    tfjs.converters.save_keras_model(model, SAVED_JS_MODEL_PATH)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if DO_TRAIN_DATA_AUGMENTATION:\n",
    "    # To prevent augemnting already augmented files\n",
    "    adprep.remove_augmented_files(adprep.TRAIN_DATASET_PATH)\n",
    "    adprep.augment_dataset(adprep.TRAIN_DATASET_PATH)\n",
    "\n",
    "adprep.preprocess_dataset(adprep.TRAIN_DATASET_PATH, adprep.TRAIN_JSON_PATH, \"Train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adprep.convert_to_wav_dataset(adprep.TESTING_DATASET_PATH)\n",
    "adprep.preprocess_dataset(adprep.TESTING_DATASET_PATH, adprep.TESTING_JSON_PATH, \"Test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model=None, load_model=True):\n",
    "    \n",
    "    X_test, y_test = prepare_dataset(TEST_DATA_PATH, test_only=True)\n",
    "    \n",
    "    # create network\n",
    "    input_shape = (X_test.shape[1], X_test.shape[2], 1)\n",
    "    \n",
    "    if load_model and model == None:\n",
    "        print(\"Loading Saved Model\")\n",
    "        model = tf.keras.models.load_model(SAVED_MODEL_PATH)\n",
    "    \n",
    "    plot_confusion_matrix(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        model\n",
    "    )\n",
    "\n",
    "    # evaluate network on test set\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(\"\\nTest loss: {}, test accuracy: {}\".format(test_loss, 100*test_acc))\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    rounded_predictions = np.argmax(y_pred, axis=1)\n",
    "    print(\"Labels:\", LABELS)\n",
    "    gt_labels =  [LABELS[x] for x in y_test]\n",
    "    predictions = [LABELS[x] for x in rounded_predictions]\n",
    "    \n",
    "    for gt, pred in zip(gt_labels, predictions):\n",
    "        print(\"GT:\", gt, \"Prediction:\", pred)\n",
    "    \n",
    "    #ipdb.set_trace()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = test_model(load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_file(file_path, model):\n",
    "\n",
    "    processed_audio = adprep.preprocess_single_file(file_path)\n",
    "    \n",
    "    output_vector = model.predict(processed_audio)\n",
    "    predict_label_id = np.argmax(output_vector, axis=1)\n",
    "    return LABELS[predict_label_id[0]], np.max(output_vector)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_file(\"testing_dataset/ajoonee/Ajooni_20Bhupy.wav\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
